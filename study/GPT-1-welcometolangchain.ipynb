{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LLM - Large Language Model 호출\n",
    "2. Chat - model 사용\n",
    "3. LLM과 chat model 의 차이점\n",
    "\n",
    "- 세부사항에 있다. 예를 들어 사용 모델(text-davinci-003 / gpt-3.5-turbo),\n",
    "- chat model 이 훨씬 싸다.\n",
    "\n",
    "랭체인을 사용하면 llm 모델들에 접근할 수 있다. 쉽게\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is a high-level, versatile, and interpreted programming language known for its simplicity and readability. It is widely used for web development, data analysis, artificial intelligence, scientific computing, and more. Python code is typically easy to write and understand, making it a popular choice for beginners and experienced programmers alike.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# chat model: 대화에 특화된 모델\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "# 대화에 특화되어 있어서 꼭 질문을 보내지 않아도 된다.\n",
    "# 메세지를 보내보자.\n",
    "chat.predict(\"what is python?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llm 과 chat model 둘 다 텍스트를 predict 할 수 있다.  \n",
    "chat model 은 대화에 최적화되어 있는데, 단지 질문을 받을 수 있을 뿐 아니라, 대화를 할 수 있다.\n",
    "\n",
    "대화. 즉, 여러 메세지 묶음이라는 의미.  \n",
    "상대로서 대화의 맥락에 맞게 대답할 수 있다는 뜻이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 의 설정 바꾸기 - 모델의 constructure 에서 할 수 있다.\n",
    "chat = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_messages\n",
    "\n",
    "위에서는 텍스트를 predict 하는 방법을 살펴 봤다.  \n",
    "질문을 했더니 답변을 받았지.\n",
    "\n",
    "이번에는 message 들을 predict 해보자.\n",
    "\n",
    "우선 message constructor 들을 import 해야한다.\n",
    "\n",
    "HumanMessage 는 사람이 보내는 것.  \n",
    "AIMessage 는 AI에 의해 보내지는 것이다.  \n",
    "SystemMessage 는 우리가 LLM에 설정들을 제공하기 위한 Message 이다.\n",
    "\n",
    "아래 messages: list 를 작성해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a geography expert. and you only reply in korean\",\n",
    "    ),\n",
    "    AIMessage(content=\"안녕, 나는 폴이야.\"),\n",
    "    HumanMessage(content=\"서울과 부산사이의 거리는 얼마인가? 그리고 너의 이름은?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SystemMessage - 이걸로 우린 AI에 일종의 기본 설정, 기본 값, 기본 context를 설정한 것이다.\n",
    "\n",
    "AIMessage - string을 미리 만들어두고 가상의 대화를 만들었다. (답변한 것처럼 가정)\n",
    "\n",
    "HumanMessage - 사용자로서 질문.\n",
    "\n",
    "단순히 string들을 predict하는 것 대신 predict_messages 를 사용하고 message의 list를 넘겨준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='서울과 부산 사이의 거리는 약 325km입니다. 제 이름은 폴이에요.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "string을 predict 하는 것과  \n",
    "message들의 list인 messages를 predict 하는 것의 차이.\n",
    "\n",
    "다음으로는 위에서 만든 대화 messages 를 조금 더 커스터마이징 하는 방법에 대해 알아보자.\n",
    "지금은 message를 우리가 하드코딩하고 있으니까.\n",
    "\n",
    "하드코딩 대신 일종의 placeholder 를 넣는다면 prompt 를 더 유용하게 만들 수 있다.\n",
    "\n",
    "- 'korean 대신 {language} '\n",
    "- '폴 대신 {name}'\n",
    "- '서울 대신 {city_a}'\n",
    "- '부산 대신 {city_b}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a geography expert. and you only reply in {language}\",\n",
    "    ),\n",
    "    AIMessage(content=\"안녕, 나는 {name}이야.\"),\n",
    "    HumanMessage(content=\"{city_a}과 {city_b}사이의 거리는 얼마인가? 그리고 너의 이름은?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Templates\n",
    "\n",
    "prompt 는 llm과 의사소통을 할 수 있는 유일한 방법이기 때문에 매우 중요하다.  \n",
    "그렇기 떄문에 prompt의 성능이 좋다면 LLM의 답변도 좋아질 것이다.\n",
    "\n",
    "매우 중요!! Prompt!!!!\n",
    "\n",
    "prompt끼리 결합도 할 수있고, 저장하거나 불러올 수도 있다.\n",
    "\n",
    "chat prompt template 이전에, 일반 prompt template 을 먼저 살펴보자.\n",
    "\n",
    "normal prompt template 는 text를 predict할 때 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울과 부산사이의 거리는 얼마인가?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normal prompt template - 그냥 string을 이용해서 template를 만든다.\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"{city_a}과 {city_b}사이의 거리는 얼마인가?\")\n",
    "\n",
    "# format으로 유효성 검사 - 만약 placeholder로 지정한 곳에 값을 넣지 않으면 에러 발생.\n",
    "template.format(city_a=\"서울\", city_b=\"부산\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "template.format()을 실행하면 string이 return 된다.   \n",
    "\n",
    "template를 확인했으면 prompt 변수에 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(city_a=\"서울\", city_b=\"부산\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 template를 만들었고, format 메서드의 호출 결과를 prompt에 저장.\n",
    "\n",
    "prompt가 있다면 이제 predict 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울과 부산 사이의 거리는 약 325km 입니다.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 작성하는 과정에서 template.format과 predict를 반복해서 작성하는 게 귀찮다고 느낄 수 있다.  \n",
    "이 후 langchain expression language 라는 것의 사용으로 template를 format 한 후 chat model 에게 전달하고 predict 를 호출하는 과정까지  \n",
    "한 줄의 코드로 구현하게 될 것이다. 좀만 기둘..\n",
    "\n",
    "전체코드 살펴보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between 부평 (Bupyeong) and 송도 (Songdo) in South Korea is approximately 10 kilometers (6.2 miles) by road.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# chat model: 대화에 특화된 모델\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {city_a} and {city_b}.\"\n",
    ")\n",
    "\n",
    "prompt = template.format(city_a=\"부평\", city_b=\"송도\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatPromptTemplate 로 위 코드를 개선해보자.\n",
    "\n",
    "ChatPromptTemplate를 import 하면 from langchain.schema import HumanMessage, AIMessage, SystemMessage 를 작성하지 않아도 좋다.  \n",
    "ChatPromptTemplate.from_messages() 를 사용한다.\n",
    "\n",
    ".from_messages 에는 똑같이 message_list를 전달한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat prompt template - template를 messages 로부터 만든다.\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(\n",
    "#         content=\"You are a geography expert. and you only reply in {language}\",\n",
    "#     ),\n",
    "#     AIMessage(content=\"안녕, 나는 {name}이야.\"),\n",
    "#     HumanMessage(content=\"{city_a}과 {city_b}사이의 거리는 얼마인가? 그리고 너의 이름은?\"),\n",
    "# ]\n",
    "\n",
    "\n",
    "# messages 는 from_messages 의 내용으로 들어간다.\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. and you only reply in {language}\"),\n",
    "    (\"ai\", \"안녕, 나는 {name}이야.\"),\n",
    "    (\"human\", \"{city_a}과 {city_b}사이의 거리는 얼마인가? 그리고 너의 이름은?\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "message를 format하기 위해서 template.format_message() 를 실행해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a geography expert. and you only reply in korean'),\n",
       " AIMessage(content='안녕, 나는 폴이야.'),\n",
       " HumanMessage(content='부평과 송도사이의 거리는 얼마인가? 그리고 너의 이름은?')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template.format_messages(\n",
    "    language=\"korean\",\n",
    "    name=\"폴\",\n",
    "    city_a=\"부평\",\n",
    "    city_b=\"송도\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "template 를 확인했으면 prompt 에 넣어준다.  \n",
    "그리고 LLM에게 보내보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='부평과 송도 사이의 거리는 약 20km 정도입니다. 제 이름은 폴이에요.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = template.format_messages(\n",
    "    language=\"korean\",\n",
    "    name=\"폴\",\n",
    "    city_a=\"부평\",\n",
    "    city_b=\"송도\",\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음(langchain expression language)으로 나아가기 전에 output parser에 대해서 조금 알아보자.  \n",
    "\n",
    "Output Parser 는 LLM의 output을 구조별로 parse(파싱) 할 수 있게 해준다.\n",
    "\n",
    "langchain expression language 는 우리의 코드를 굉장히 줄여준다.  \n",
    "그리고 다양한 template 와 LLM 호출, 서로 다른 응답(response)을 함께 사용하게 해준다.  \n",
    "\n",
    "\n",
    "일단 먼저, Output Parser 를 만드는 것부터 해보자.\n",
    "\n",
    "output parser가 필요한 이유는, LLM의 응답(response)을 변형해야 할 때가 있기 때문이다.  \n",
    "\n",
    "이번에는 응답을 list 로 변환시키는 것을 만들어보자.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종종 LLM의 응답을 변형시키고 싶을때가 생길것이다.  \n",
    "왜냐하면 LLM은 항상 텍스트로만 응답하니까 그 응답을 무언가로 변형(transform)시키고 싶을 거다.  \n",
    "데이터베이스에 넣을 형태라던지, dictionary 또는 tuple에 저장할 수 있도록 말이다.  \n",
    "\n",
    "이것이 바로 output parser 가 필요한 이유이다.\n",
    "\n",
    "먼저 BaseOutputParser 를 불러와서 사용해보자.  \n",
    "BaseOutputParser 는 parse 라는 메서드를 꼭 구현해야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello, how, are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='MERCURY, VENUS, EARTH, MARS, JUPITER, SATURN, URANUS, NEPTUNE')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    # 최대 max_items 개 만큼 리스트를 만들어줘라, list가 아닌 것으로는 답을 하지 말아라.\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in uppercase. Do not reply with anything elss.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the planets?\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputparser 사용해보자.  \n",
    "\n",
    "predict한 결과값을 result에 담아서 parse 해보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MERCURY',\n",
       " 'VENUS',\n",
       " 'EARTH',\n",
       " 'MARS',\n",
       " 'JUPITER',\n",
       " 'SATURN',\n",
       " 'URANUS',\n",
       " 'NEPTUNE',\n",
       " 'PLUTO']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # 최대 max_items 개 만큼 리스트를 만들어줘라, list가 아닌 것으로는 답을 하지 말아라.\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in uppercase. Do not reply with anything elss.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(max_items=10, question=\"What are the planets?\")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 LLM으로부터 성공적으로 응답을 받았다.  \n",
    "\n",
    "prompt template를 사용했고  \n",
    "prompt template을 포맷팅 한 후에 output parse를 사용했다.\n",
    "\n",
    "우리가 한 작업들을 보면 코드가 너무 많다.  \n",
    "message format, predict 호출, 이후 parser 만들고 parse method 까지.  \n",
    "우리는 더 나은 방법이 필요하다. 그리고 실제로 더 좋은 방법이 있다.\n",
    "\n",
    "Langchain expression language 표현언어에 대해서 알아보자.  \n",
    "우리에게 필요한 건 template, output parser 그리고 chat model 이 전부이다.  \n",
    "우리가 만들 건 <b>\"Chain\"</b> 이다.  \n",
    "\n",
    "'Chain'이라는 것은 기본적으로 모든 요소를 합쳐주는 역할을 한다.  \n",
    "합쳐진 요소들은 하나의 chain으로 실행될 것이고, 하나하나 순서대로 result를 반환할 때 까지 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인이 | 기호에 마법을 부여해준다.\n",
    "chain = template | chat | CommaOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 Chain은 template, language model, 그리고 output parser로 구성되어 있다.  \n",
    "chain을 작동시켜보자.  \n",
    "chain.invoke() - invoke 메서드의 입력값으로는 dictionary 타입이 들어가야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIKACHU', 'BULBASAUR', 'CHARIZARD', 'SQUIRTLE', 'JIGGLYPUFF']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# placeholder를 채워줘라\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"max_items\": \"5\",\n",
    "        \"question\": \"What are the pokemons?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 코드를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIKACHU', 'BULBASAUR', 'CHARIZARD', 'SQUIRTLE', 'EEVEE']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# chat model: 대화에 특화된 모델\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # 최대 max_items 개 만큼 리스트를 만들어줘라, list가 아닌 것으로는 답을 하지 말아라.\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in uppercase. Do not reply with anything elss.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 랭체인이 | 기호에 마법을 부여해준다.\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "# placeholder를 채워줘라\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"max_items\": \"5\",\n",
    "        \"question\": \"What are the pokemons?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드가 많이 단축된게 보일 것이다.\n",
    "\n",
    "물론 PromptTemplate, OutputParser, chat model 코드가 있긴 하다.  \n",
    "하지만 우리가 한 것은 모든걸 한줄로 늘어놓은게 다 이다.  \n",
    "랭체인 내부에서는 우리를 위해 .format_messages()를 호출하고, 그 다음에 chat.predict 도 호출하고, 마지막으로 parse를 호출해 준 것이다.   \n",
    "이 모든건 invoke() 호출 한방이다.\n",
    "\n",
    "이 문법과 함께한다면 더 멋진 일들을 많이 할 수 있다.  \n",
    "왜냐하면 이걸로 chain 들 끼리도 결합을 할 수 있기 때문이다.  \n",
    "\n",
    "예를 들어)\n",
    "chain_one = template | chat | CommaOutputParser()  \n",
    "chain_two = template_2 | chat2 | OutputParser()  \n",
    "\n",
    "all = chain_one | chain_two | output3\n",
    "\n",
    "먼저 chain_one 을 넣고 그 출력값을 chain_two 의 입력값으로 사용할 수 있다.  \n",
    "거기에 또 다른 output parser도 놓을 수 있지(output3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain expression language 표현언어에 대해 조금 더 살펴보자.  \n",
    "\n",
    "먼저 구성요소(component)부터 살펴보자.  \n",
    "chain이 가질 수 있는 구성요소는 다음과 같다.  \n",
    "- prompt\n",
    "- retriever\n",
    "- llm, chatmodel\n",
    "- tool\n",
    "- outputparser\n",
    "\n",
    "우리는 이 전에 Prompt, Chatmodel, OutputParser 를 사용했다.  \n",
    "prompt 의 입력타입은 Dictionary, 출력타입은 PromptValue,  \n",
    "chatmodel의 입력타입은 single string, list of chat messages or a PromptValue, 출력타입은 ChatMessage,  \n",
    "ouputParser의 입력타입은 ChatMessage or LLM . \n",
    "\n",
    "이제 무슨일이 일어나는지 이해할 수 있을 것이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"max_items\": \"5\",\n",
    "        \"question\": \"What are the pokemons?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에 \n",
    "```python\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"max_items\": \"5\",\n",
    "        \"question\": \"What are the pokemons?\",\n",
    "    }\n",
    ")\n",
    "```\n",
    "dictionary 값은 template 에 주어지고, template의 반환값은 chat으로 전달된다.  \n",
    "그리고 chat의 반환값은 OutputParser에게 전달된다.  \n",
    "\n",
    "chain은 단지 component의 그룹 혹은 나열이라고 보면 될 것이다.  \n",
    "각 구성요소는 입력값을 받아서 출력값을 반환한다.  \n",
    "각 출려값은 chain에 입력한 코드가 끝날 때까지 옆의 구성요소에게 전달되고 사용자는 최종 출력값을 전달받는 것이다.\n",
    "\n",
    "\n",
    "두 개의 chain끼리 연결하는 걸 해보자.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# 요리사\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"너는 세계 레벨의 요리사야. 너는 어떤 종류의 요리든 쉽게 구할 수 있는 재료로 따라하기 쉬운 레시피를 만들어낼 수 있어.\"),\n",
    "    (\"human\", \"나는 {cuisine}를 요리하고 싶어요.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비건 요리사\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"너는 채식주의자를 위한 요리사야. 전통적인 채식주의자용 레시피에 특화되어 있어. 너는 대체 재료를 찾고, 준비하는 방법에 대해 설명해줄수있어. 대신, 기존 레시피를 너무 많이 변경해서는 안돼. 만약 대체품이 없다면 그냥 모른다고 말해줘.\"),\n",
    "    (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 chain 을 만들어보자.  필요한 입력값들이 뭔지 생각해보자.\n",
    "\n",
    "일단 recipe 가 하나의 입력값이 될 것이다.  \n",
    "그리고 그 다음은 cuisine.\n",
    "\n",
    "chef_chain 이 첫 번째 chain이 될 것이다.  \n",
    "왜냐하면 먼저 레시피 값을 얻고, 그 다음 채식주의자 레시피로 변경해야 하니까."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='이 레시피는 매우 간단하고 맛있어 보이네요! 채식주의자를 위해 대체할 수 있는 재료가 있을까요? 계란은 채식주의 식단에 포함되지 않는데, 대체할 수 있는 재료로는 토푸, 두부, 또는 식물성 달걀 대체품이 있습니다. 계란 대신 토푸를 사용하면 비슷한 식감을 낼 수 있을 것 같아요. 토푸를 물에 삶아서 계란 대신 사용하면 될 것 같습니다. 계란 대신 토푸를 사용하여 라면을 만들어보세요!')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final_chain = chef_chain | veg_chain\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\"cuisine\": \"라면\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 동작하니 전체 코드로 살펴보자.\n",
    "+ streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋아요! 라면은 매우 쉽게 만들 수 있는 요리입니다. 다음은 간단한 라면 레시피입니다.\n",
      "\n",
      "재료:\n",
      "- 라면 봉지 1개\n",
      "- 물 2컵\n",
      "- 계란 1개\n",
      "- 녹말가루 1큰술\n",
      "- 소금 약간\n",
      "- 후추 약간\n",
      "- 김가루 약간\n",
      "- 파 또는 대파 약간\n",
      "\n",
      "1. 물을 냄비에 넣고 끓입니다.\n",
      "2. 물이 끓기 시작하면 라면 봉지를 넣고 3분간 삶아줍니다.\n",
      "3. 계란을 껍질을 벗겨 볼에 깨뜨려 넣고 녹말가루와 소금을 넣어 풀어줍니다.\n",
      "4. 라면에 계란물을 넣고 잘 섞어줍니다.\n",
      "5. 후추를 약간 넣고 김가루와 파를 올려 완성합니다.\n",
      "\n",
      "간단하고 맛있는 라면 요리 완성! 맛있게 드세요.이 라면 레시피는 매우 간단하고 맛있어 보이네요! 만약 채식주의자를 위한 대체 재료를 사용하고 싶다면, 계란 대신 토푸를 사용할 수 있습니다. 토푸는 대체로 계란과 비슷한 맛과 질감을 제공해주는 대체품이에요. \n",
      "\n",
      "대체로 계란 대신 토푸를 사용할 때는, 토푸를 깨끗이 씻어서 물기를 제거하고 녹말가루와 소금을 섞어 계란물을 만드는 단계에서 토푸를 사용하면 됩니다. 그 외의 과정은 동일하게 따라가면 됩니다. \n",
      "\n",
      "채식주의자용 라면 레시피로서 토푸를 사용하면 계란 대신 대체재료를 활용하여 맛있는 채식주의자용 라면을 즐길 수 있을 거에요."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='이 라면 레시피는 매우 간단하고 맛있어 보이네요! 만약 채식주의자를 위한 대체 재료를 사용하고 싶다면, 계란 대신 토푸를 사용할 수 있습니다. 토푸는 대체로 계란과 비슷한 맛과 질감을 제공해주는 대체품이에요. \\n\\n대체로 계란 대신 토푸를 사용할 때는, 토푸를 깨끗이 씻어서 물기를 제거하고 녹말가루와 소금을 섞어 계란물을 만드는 단계에서 토푸를 사용하면 됩니다. 그 외의 과정은 동일하게 따라가면 됩니다. \\n\\n채식주의자용 라면 레시피로서 토푸를 사용하면 계란 대신 대체재료를 활용하여 맛있는 채식주의자용 라면을 즐길 수 있을 거에요.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "# 요리사\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"너는 세계 레벨의 요리사야. 너는 어떤 종류의 요리든 쉽게 구할 수 있는 재료로 따라하기 쉬운 레시피를 만들어낼 수 있어.\"),\n",
    "        (\"human\", \"나는 {cuisine}를 요리하고 싶어요.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "# 비건 요리사\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"너는 채식주의자를 위한 요리사야. 전통적인 채식주의자용 레시피에 특화되어 있어. 너는 대체 재료를 찾고, 준비하는 방법에 대해 설명해줄수있어. 대신, 기존 레시피를 너무 많이 변경해서는 안돼. 만약 대체품이 없다면 그냥 모른다고 말해줘.\",\n",
    "        ),\n",
    "        (\"human\", \"{recipe}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "# 최종 chain\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\"cuisine\": \"라면\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 최종 chain 을 만든 부분을 보면 langchaing 언어로 되어 있는데\n",
    "```python\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "final_chain.invoke({\"cuisine\": \"라면\"})\n",
    "```\n",
    "이 코드는 langchain이 코드({\"recipe\": chef_chain})를 먼저 실행하고 응답 결과를 다음(veg_chain)으로 전달하도록 한다.  \n",
    "이 걸 RunnableMap 이라고 한다.  앞에 것이 먼저 실행되고, 그 출력 값이 chain의 다음 요소에게 전달되는 것!\n",
    "이렇게 하는 이유는 veg_chain에 recipe 값이 필요하기 때문이다.  \n",
    "\n",
    "veg_chain이 호출되면 처음에는 prompt가 호출되고, prompt의 결과값은 chat에게 전달된다.\n",
    "prompt는 필요로 하는 값을 전달받아야 하는데, 여기서는 recipe이 그것이다.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
