{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랭체인에는 5가지 정도 종류의 메모리가 있다.\n",
    "각자 저장 방식도 다르고 각자만의 장단점이 있다.\n",
    "\n",
    "챗봇에 메모리를 추가하지 않으면 챗봇은 아무것도 기억할 수 없다.\n",
    "\n",
    "오픈AI에서 제공하는 기본 API는 랭체인 없이 사용할 수 있는데 메모리를 지원하지 않는다.(stateless)  \n",
    "즉, 모델에게 어떤 말을 건네면 모델은 답을 한 직후에 모든 대화 내용을 까먹게 된다.(저장 X)\n",
    "\n",
    "챗GPT에는 메모리가 탑재되어 있기 때문에 대화하는 느낌을 들게 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫 번째 메모리는 Conversation Buffer Memory 라고 한다.\n",
    "\n",
    "이 메모리는 단순하다. 그냥 이전 대화 내용 전체를 저장하는 메모리이다.   \n",
    "이 메모리의 단점은 대화 내용이 길어질수록 메모리도 커지니까 비효율적이라는 것.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"how are  you?\"},\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hi22\"},\n",
    "    {\"output\": \"how are  you?222\"},\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 메모리는 text completion 할때 유용하다. \n",
    "- 예측을 해야할 때.\n",
    "- 텍스트를 자동완성하고 싶을 때.\n",
    "\n",
    "그러나 만약 챗모델과 작업을 하면 AI메세지와 Human 메세지가 다 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원한다면 다음과 같이 작성할 수 있다.\n",
    "\n",
    "```python\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "```\n",
    "\n",
    "알아둬야 하는 건 메모리 종류와 무관하게 API들은 다 똑같다는 점이다!  \n",
    "모든 메모리는 save_context, load_memory_variables 라는 함수를 갖고 있다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"how are  you?\"},\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"how are  you?\"},\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"how are  you?\"},\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"how are  you?\"},\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history 를 보면 HumanMessage랑 AIMessage로 바뀌었다.\n",
    "\n",
    "---\n",
    "\n",
    "앞으로 배워볼 다른 메모리를도 동일한 API를 갖고 있다는 사실을 알아두자.\n",
    "\n",
    "우선 메모리를 만들고, 챗모델을 위한건지 아닌지 선택하고,  \n",
    "\n",
    "챗 모델을 위한 게 아니라면 False 또는 아예 return_message를 빼도 된다.  \n",
    "\n",
    "그러면 history가 문자열로 표시될 것이다.\n",
    "\n",
    "챗모델을 사용하고 싶다면? return_message=True 로 설정하면 된다.  \n",
    "\n",
    "그러면 챗모델이 사용할 수 있는 형태로 출력이 된다.\n",
    "\n",
    "API 는 메모리 종류와 상관없이 다 똑같다.\n",
    "\n",
    "save_context - input, output 다 똑같고,\n",
    "\n",
    "대화 기록을 불러오기 위해선 load_memory_variables 라는 함수를 실행.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 번째는 Conversation Buffer Window Memory 에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationBufferMemory 와 다르게 ConversationBufferWindowMemory 는  \n",
    "대화의 특정 부분만을 저장하는 메모리다.\n",
    "\n",
    "예를 들어 제일 최근 5개의 메세지만 저장한다고 하면  \n",
    "6번째 메세지가 추가 됐을 때 가장 오래된 메세지는 버려지는 방식이다.\n",
    "\n",
    "메모리를 특정 크기로 유지할 수 있다는 게 이 ConversationBufferWindowMemory의 큰 장점이다.  \n",
    "단점은 챗봇이 전체가 아닌 최근 대화에만 집중한다는 것.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    # k =  버퍼 윈도우의 사이즈: 몇 개의 메세지를 저장할지\n",
    "    k=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메세지를 추가 하기 쉽게 함수를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(input, output):\n",
    "    memory.save_context(\n",
    "        {\"input\": input},\n",
    "        {\"output\": output},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 메세지를 추가해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(1, 1)\n",
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(5, 5)\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세 번째는 ConversationSummaryMemory\n",
    "\n",
    "ConversationSummaryMemory 는 llm을 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, 메모리를 실행하는 데 비용이 든다는 뜻."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationSummaryMemory는 message 그대로 저장하는 것이 아니라   \n",
    "conversation의 요약을 자체적으로 해주는 것이다.\n",
    "\n",
    "초반에는 ConversationSummaryMemory는 이전보다 더 많은 토큰과 저장공간을 차지하게 될거다.  \n",
    "하지만 conversation 버퍼 메모리를 사용하고 있어서 대화가 진행될 수록 저장된 모든 메세지가 매우 많아지면서 잘 연결될 것이다. \n",
    "\n",
    "conversation 메세지가 많아질수록 ConversationSummaryMemory 의 도움을 받아 요약하는 것이 토큰의 양도 줄어들면서 훨씬 나은 방법이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history():\n",
    "    return memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces themselves as Nicolas from South Korea. The AI responds by expressing admiration for Nicolas's location.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces themselves as Nicolas from South Korea. The AI responds by expressing admiration for Nicolas's location and wishes it could go there.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"South korea is so beautiful\", \"I wish I could go!!!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces themselves as Nicolas from South Korea. The AI responds by expressing admiration for Nicolas's location and wishes it could go there. Nicolas mentions that South Korea is cold today, and the AI expresses a desire for it to turn warm.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"South korea is so cold today\", \"I wish It turns warm!!!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces themselves as Nicolas from South Korea. The AI responds by expressing admiration for Nicolas's location and wishes it could go there. Nicolas mentions that South Korea is cold today, and the AI expresses a desire for it to turn warm.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네 번째는 ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversation Summary Memory, Conversation Buffer Memory 의 결합이다.  \n",
    "이것이 하는 일은, 메모리에 보내온 메세지의 수를 저장하는 것이다.\n",
    "\n",
    "또한 우리가 limit에 다다른 순간, 그냥 무슨 일이 일어났는지 잊어버리는 것 대신  \n",
    "오래된 메세지들을 summarize(요약) 할 것이다.  \n",
    "즉, 가장 최근의 상호작용을 계속 추적한다는 것.  \n",
    "\n",
    "주고받은 메세지 모두 잊혀지지 않고 요약됨.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_token_limit - 이것은 가능한 메세지 토큰 수의 최대값을 의미한다. 메세지들이 요약되기 전에."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat,\n",
    "    max_token_limit=150,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context(\n",
    "        {\"input\": input},\n",
    "        {\"output\": output},\n",
    "    )\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "get_history()\n",
    "\n",
    "# add_message(\"South korea is so beautiful\", \"I wish I could go!!!\")\n",
    "\n",
    "# get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_history를 실행해 보면 우리는 메세지를 그대로 저장하고 있다.\n",
    "```python\n",
    "{'history': \"Human: Hi I'm Nicolas, I live in South Korea\\nAI: Wow that is so cool!\"}\n",
    "```\n",
    "return_messages 를 True로 지정해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat,\n",
    "    max_token_limit=80,\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return_messages 를 True로 설정하는 이유는 이것을 채팅 모델에 사용할 것이기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문을 하나 더 해보고 다시 history를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"South korea is so beautiful\", \"I wish I could go!!!\")\n",
    "\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Korea from Argentina?\", \"I don't know! Super far!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Brazil from Argentina?\", \"I don't know! Super far!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 보는것처럼 limit에 도달하면 오래된 메세지들이 요약되어서 보인다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다섯번 째는 Conversation Knowledget Graph Memory 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것도 llm 사용.  \n",
    "이건 대화 중의 엔티티의 knowledget graph를 만든다.  \n",
    "\n",
    "가장 중요한 것들만 뽑아내는 요약본 같은 것.\n",
    "\n",
    "knowledge graph에서 히스토리를 가지고 오지 않고 엔티티를 가지고 오기 때문에 get_history 는 지웠다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationKGMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(\"Hi, I'm Yoon, I live in South Korea\", \"Wow that is so awesome!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Hi, I'm Yoon, I live in South Korea\" 라는 메세지를 보내고, Memory를 불러와보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({\"input\": \"who is yoon\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약하자면 대화에서 entity를 뽑아내는 것이라 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"yoon likes money\", \"wow that is true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({\"input\": \"what deos yoon like?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 다 수동으로 정보를 입력하면 챗봇이 이걸 어떻게 활용하게 될까?\n",
    "\n",
    "뒤에 memory를 사용하는 다른 chain들을 살펴보고 이걸 활용할 수 있는 쉬운 방법을 알아보자.    \n",
    "계속 .save_context 하고 .load_memory_variables를 계속 하는 건 번거롭다.  \n",
    "뒤에 자동으로 즉시 메모리를 활용할 수 있는 방법이 있다.  \n",
    "그럼 load_memory_variables를 할 필요도 없고 save_context를 할 필요도 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
