{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are eight planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "b = chat.predict(\"How many planets are there?\")\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 모델의 창의성 결정: temperature\n",
    "# low temperature: 창의적이지 않음, \n",
    "# high temperature: 창의적, 무작위성을 갖음\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri. Come posso aiutarti oggi?')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "텍스트 predict: 질문을 하고 답변을 받는다.\n",
    "\n",
    "message 들을 predict 해보자.\n",
    "우선 message constructor들을 import 한다.\n",
    "\n",
    "AIMessage: AI에 의해 보내지는 것\n",
    "SystemMessage: 우리가 LLM에 설정들을 제공하기 위한 Message\n",
    "\n",
    "\n",
    "predict 와 predict_messages 의 차이?\n",
    "string을 predict 하는 것과 message 들의 list 인 messages 를 predict 하는 것의 차이.\n",
    "'''\n",
    "\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    \n",
    "    # AI에 일종의 기본 설정, 기본값, 기본 context 를 설정.\n",
    "    SystemMessage(\n",
    "        content=\"You are a geography expert. And you only reply in Italian.\",\n",
    "    ),\n",
    "    \n",
    "    # AI 가 이미 메세지를 보낸 것으로 가정\n",
    "    # - string을 미리 만들어두고 일종의 가상 대화를 만듬.\n",
    "    AIMessage(\n",
    "        content=\"Ciao, mi chiamo Paolo!\",\n",
    "    ),\n",
    "    \n",
    "    # 사람이 질문한다고 가정\n",
    "    # - 사용자로서 질문\n",
    "    HumanMessage(\n",
    "        content=\"What is the distance between Mexico and Thailand. Also, What is your name?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 단순히 string들을 predict 하는 것 대신에 \n",
    "# predict_messages 를 사용하고 message의 list를 넘겨준다.\n",
    "chat.predict_messages(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the distance between Mexico and Thailand.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" python\n",
    "Prompt Templates\n",
    "\n",
    "# 설정값들을 전달하고 싶지 않은 경우\n",
    "PromptTemplate: 그냥 string을 이용해서 template 을 만든다.\n",
    "ex) \n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}.\",\n",
    ")\n",
    "\n",
    "먼저 template 를 만들고, format메서드의 호출 결과를 prompt에 저장.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# 설정값들을 전달하고 싶지 않은 경우\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}.\",\n",
    ")\n",
    "\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "chat.predict(prompt)\n",
    "'''\n",
    "위 과정에서 template.format 과 predict를 반복해서 작성하는게 귀찮다고 느낄 수 있다.\n",
    "뒤에 template을 format한 후 chat model에게 전달하고 predict를 호출하는 과정까지 \n",
    "말 그대로 한 줄의 코드로 구현하게 될 것이다.\n",
    "이걸 먼저 하지 않는 이유는 이걸 보면 말 그대로 마법을 보는 것 같기 떄문에,\n",
    "각 component(구성요소) 를 이해하기 어렵기 때문이야\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles) when measured in a straight line.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" python\n",
    "Prompt Templates\n",
    "\n",
    "# 설정값 전달\n",
    "ChatPromptTemplate: template을 message로부터 만든다.\n",
    "ex) \n",
    "\n",
    "먼저 template 를 만들고, format메서드의 호출 결과를 prompt에 저장.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# 설정값 전달\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}.\",\n",
    ")\n",
    "\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 멕시코와 태국 사이의 거리는 약 16,000km입니다. 제 이름은 소크라테스입니다.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ChatPromptTemplate.from_messages\n",
    "똑같이 messages list를 전달할 거지만, 좀 더 변형을 한다.\n",
    "\n",
    "('message type', 'content')\n",
    "\n",
    "시스템메세지 : GPT에게 보내는 프롬프트\n",
    "AI메세지     :  \n",
    "휴먼메세지   :  \n",
    "\n",
    "SystemMessage(content=\"You are a geography expert. And you only reply in Italian.\"),\n",
    "-> (\"system\", \"You are a geography expert. And you only reply in Italian.\")\n",
    "\n",
    "AIMessage(content=\"Ciao, mi chiamo Paolo!\") \n",
    "-> (\"ai\", \"Ciao, mi chiamo Paolo!\")\n",
    "    \n",
    "HumanMessage(content=\"What is the distance between Mexico and Thailand. Also, What is your name?)\n",
    "-> (\"human\", \"What is the distance between Mexico and Thailand. Also, What is your name?\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Ciao, mi chiamo {name}!\"),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"What is the distance between {country_a} and {country_b}. Also, What is your name?. Also, what is your name?\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"korean\",\n",
    "    name=\"Socrates\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thiland\",\n",
    "    )\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" OutputParser 와 LangChain expression language(표현언어)\n",
    "LangChain expression language(표현언어)는 우리의 코드를 굉장히 줄여줄 것이다.\n",
    "그리고 다양한 template 와 llm 호출, 그리고 서로 다른 응답(response)을 함께 사용하게 해준다.\n",
    "\n",
    "1. Output Parser 만들기\n",
    "Output Parser가 필요한 이유?\n",
    "- llm의 응답을 변형해야 할 때가 있기 때문, \n",
    "- 이번에는 응답을 list 로 변환시키는 것을 만들어 보자.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello, how, are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='red, blue, green, yellow, orange, purple, pink, black, white, brown'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply with anything else.\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the colors?\",\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content)\n",
    "'''output parse\n",
    "LLM 으로부터 성공적으로 응답 받음\n",
    "- prompt template 사용.\n",
    "- prompt template 포맷팅 한 후 output Parser 사용.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charmander', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"더 나은 방법\n",
    "우리에게 필요한 건 template 와 output parser 그리고 chat model\n",
    "\n",
    "- 체인 chain 만들기\n",
    "'chain'이라는 것은 기본적으로, 모든 요소를 합쳐주는 역할을 한다.\n",
    "합쳐진 요소들은 하나의 체인으로 실행된다. 하나하나 순서대로 result를 반환할때까지.\n",
    "\n",
    "- 랭체인의 | 기호 사용.\n",
    "chain = template | chat | CommaOutputParser()\n",
    "내부에서 랭체인이 우릴 위해 .format_messages를 호출하고, 그 다음에 chat.predict도 호출하고,\n",
    "마지막으로 parse를 호출한다. \n",
    "이 방법으로 훨씬 더 멋진 일들을 많이 할 수 있다.\n",
    "왜냐하면 이걸로 체인끼리 결합할 수 있기 때문.\n",
    "\n",
    "- LangChain expression language 을 통한 결합\n",
    "chain_one = template | chat | CommaOutputParser()\n",
    "chain_two = template_2 | chat | outputparser\n",
    "all = chain_one | chain_two | output\n",
    "체인 원의 출력값을 체인 투의 입력값으로 사용 가능, 그리고 또 다른 output parse 사용 가능.\n",
    "\n",
    "이런식으로\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply with anything else.\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "# chain 동작\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"max_items\": 5,\n",
    "        \"question\": \"what are the pokemons?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain expression language\n",
    "## 두 개의 체인 생성\n",
    "- 체인끼리 연결\n",
    "- 하나의 체인 실행, 그 출력값을 이용해 다른 체인을 실행할 수 있다(순차적).\n",
    "\n",
    "## 쉐프 template\n",
    "1. 레시피를 전달해주는 셰프\n",
    "- 랭체인의 prompt 중 chatprompttemplate 를 import 해와서 template 생성\n",
    "-   \n",
    "2. 전달받은 레시피를 채식주의자 레시피로 바꿔주는 셰프\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a world-class international chef. You create easy to follow recipies for any type of cuising with easy to find ingredients.\",\n",
    "        ),\n",
    "        (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{recipe}가 하나의 입력값이 된다.  \n",
    "그 다음은 {cuisine}.\n",
    "\n",
    "chef_chain이 첫 번째 chain 이 된다.  \n",
    "왜냐하면 먼저 레시피(recipe) 값을 얻고, 그 다음 채식주의 레시피로 변경할 거니까.  \n",
    "chef_chain 다음에 veg_chain 이 와야된다는게 자연스럽게 이해될 것이다.  \n",
    "\n",
    "** 한 가지 더 생각할 점은 입려값과 출력값의 이름이 일치해야 한다는 것!! **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Here's a simple recipe for Chicken Tikka Masala, a popular Indian dish that is sure to impress your friends and family.\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons paprika\n",
      "- 1 teaspoon ground turmeric\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 1 can (14 oz) crushed tomatoes\n",
      "- 1 cup heavy cream\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, mix together the yogurt, lemon juice, cumin, paprika, turmeric, garam masala, coriander, and chili powder. Add the chicken pieces and coat them well with the marinade. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. In a large skillet, heat the vegetable oil over medium heat. Add the onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute until fragrant.\n",
      "\n",
      "3. Add the marinated chicken pieces to the skillet, along with any remaining marinade. Cook for about 5-7 minutes, stirring occasionally, until the chicken is browned on all sides.\n",
      "\n",
      "4. Stir in the crushed tomatoes and season with salt and pepper. Bring the mixture to a simmer, then reduce the heat to low and cover. Let it cook for about 15-20 minutes, stirring occasionally.\n",
      "\n",
      "5. Stir in the heavy cream and cook for an additional 5 minutes, allowing the flavors to meld together. Taste and adjust seasoning if needed.\n",
      "\n",
      "6. Serve the Chicken Tikka Masala over steamed rice or with naan bread. Garnish with fresh cilantro before serving.\n",
      "\n",
      "Enjoy your homemade Chicken Tikka Masala, a delicious and flavorful Indian dish that will surely impress your guests!To make this Chicken Tikka Masala recipe vegetarian, we can replace the chicken with a plant-based alternative such as tofu or seitan. Here's how you can adapt the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb firm tofu or seitan, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt (you can use dairy-free yogurt for a vegan version)\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons paprika\n",
      "- 1 teaspoon ground turmeric\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 1 can (14 oz) crushed tomatoes\n",
      "- 1 cup coconut cream (or another dairy-free heavy cream alternative)\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "\n",
      "Instructions:\n",
      "1. Instead of marinating chicken, marinate the tofu or seitan in the yogurt and spice mixture as instructed in the recipe. Refrigerate for at least 1 hour.\n",
      "2. Follow steps 2 and 3 of the recipe as written, sautéing the onion, garlic, ginger, and marinated tofu or seitan until browned.\n",
      "3. Continue with step 4 by adding the crushed tomatoes and seasoning. Let it simmer for 15-20 minutes.\n",
      "4. Proceed with step 5 by stirring in the coconut cream and cooking for an additional 5 minutes.\n",
      "5. Serve the vegetarian Tikka Masala over rice or with naan bread, garnishing with fresh cilantro.\n",
      "\n",
      "By making these simple ingredient swaps, you can enjoy a delicious vegetarian version of Chicken Tikka Masala that retains the authentic flavors of the traditional dish."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"To make this Chicken Tikka Masala recipe vegetarian, we can replace the chicken with a plant-based alternative such as tofu or seitan. Here's how you can adapt the recipe:\\n\\nIngredients:\\n- 1 lb firm tofu or seitan, cut into bite-sized pieces\\n- 1 cup plain yogurt (you can use dairy-free yogurt for a vegan version)\\n- 2 tablespoons lemon juice\\n- 2 teaspoons ground cumin\\n- 2 teaspoons paprika\\n- 1 teaspoon ground turmeric\\n- 1 teaspoon garam masala\\n- 1 teaspoon ground coriander\\n- 1 teaspoon chili powder (adjust to taste)\\n- 2 tablespoons vegetable oil\\n- 1 onion, finely chopped\\n- 3 cloves garlic, minced\\n- 1-inch piece of ginger, grated\\n- 1 can (14 oz) crushed tomatoes\\n- 1 cup coconut cream (or another dairy-free heavy cream alternative)\\n- Salt and pepper to taste\\n- Fresh cilantro, chopped (for garnish)\\n\\nInstructions:\\n1. Instead of marinating chicken, marinate the tofu or seitan in the yogurt and spice mixture as instructed in the recipe. Refrigerate for at least 1 hour.\\n2. Follow steps 2 and 3 of the recipe as written, sautéing the onion, garlic, ginger, and marinated tofu or seitan until browned.\\n3. Continue with step 4 by adding the crushed tomatoes and seasoning. Let it simmer for 15-20 minutes.\\n4. Proceed with step 5 by stirring in the coconut cream and cooking for an additional 5 minutes.\\n5. Serve the vegetarian Tikka Masala over rice or with naan bread, garnishing with fresh cilantro.\\n\\nBy making these simple ingredient swaps, you can enjoy a delicious vegetarian version of Chicken Tikka Masala that retains the authentic flavors of the traditional dish.\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\":\"indian\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두 개의 체인\n",
    "그 중 하나는 chef_chain\n",
    "chef_prompt, chat, 그리고 LLM 으로 이루어져있다.\n",
    "\n",
    "그리고 다른 하나인 veg_chain 도 역시 beg_chef_prompt 와 chat language model 을 가지고 있다.\n",
    "\n",
    "여기서 우리가 하려던 것은 이 둘을 묶은 chain 을 만드는 것이다.  \n",
    "chef_chain의 출력값이 veg_chain의 입력값이 되게끔 ...\n",
    "그래서 final_chain 을 만들었다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
